{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import string\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tslearn.piecewise import PiecewiseAggregateApproximation\n",
    "from tslearn.piecewise import SymbolicAggregateApproximation, OneD_SymbolicAggregateApproximation\n",
    "from math import sqrt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from langdetect import detect\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Computing covariance and correlation matrix\n",
    "df = pd.read_csv('price_df.csv',index_col = 0)\n",
    "df['returns'] = df.groupby(['name'])['close'].diff()\n",
    "print(df)\n",
    "len(df['name'].unique().tolist())\n",
    "df_transposed = df.set_index(['name','day']).close.unstack('name')\n",
    "df_return = df_transposed.pct_change()\n",
    "df_return.cov()\n",
    "df_return.corr()\n",
    "\n",
    "groups = df.groupby(['name'])\n",
    "groups.get_group('AIRPORT-C8')\n",
    "groups.get_group('3Month') # have full records for 3 months\n",
    "df_new = groups.filter(lambda x : len(x)==60) #select 60 stock\n",
    "df_transposed1 = df_new.set_index(['name','day']).close.unstack('name')\n",
    "df_return1 = df_transposed1.pct_change()\n",
    "df_return1.cov()\n",
    "df_return1.corr()\n",
    "\n",
    "#positive and negative correlation\n",
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_pos_correlations(df, n):\n",
    "    au_corr = df.corr().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "def get_top_neg_correlations(df, n):\n",
    "    au_corr = df.corr().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=True)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "#Positive correlated stocks\n",
    "x = get_top_pos_correlations(df_return, n)\n",
    "y = get_top_pos_correlations(df_return1, n)\n",
    "\n",
    "print(\"Top %d Positive Correlations\" % n)\n",
    "print(\"For different range of records: \");print(x)\n",
    "print(\"Top %d Positive Correlations\" % n)\n",
    "print(\" For stocks with >60 records: \" );print(y)\n",
    "\n",
    "#Negative correlated stocks\n",
    "r = get_top_neg_correlations(df_return, n)\n",
    "s = get_top_neg_correlations(df_return1, n)\n",
    "    \n",
    "print(\"Top %d Negative Correlations\" % n)\n",
    "print(\"For different range of records: \");print(r)\n",
    "print(\"Top %d Negative Correlations\" % n)\n",
    "print(\" For stocks with >60 records: \" );print(s)\n",
    "\n",
    "\n",
    "#Find stock returns and Risk\n",
    "dfReturns = df_transposed1.apply(lambda x: np.log(x) - np.log(x.shift(1))).mean()*61\n",
    "dfReturns = pd.DataFrame(dfReturns)\n",
    "dfReturns.columns = ['Returns']\n",
    "dfReturns['Risk'] = df_transposed1.pct_change().std()*sqrt(61)\n",
    "\n",
    "#find correlation matrix between each stock\n",
    "corr = df_transposed1.corr()\n",
    "\n",
    "# generate the linkage matrix for clustering\n",
    "Z = linkage(corr, 'average')\n",
    "\n",
    "# function to create dendogram\n",
    "def fancy_dendrogram(*args, **kwargs):\n",
    "    max_d = kwargs.pop('max_d', None)\n",
    "    if max_d and 'color_threshold' not in kwargs:\n",
    "        kwargs['color_threshold'] = max_d\n",
    "    annotate_above = kwargs.pop('annotate_above', 0)\n",
    "\n",
    "    ddata = dendrogram(*args, **kwargs)\n",
    "\n",
    "    if not kwargs.get('no_plot', False):\n",
    "        plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
    "        plt.xlabel('sample index or (cluster size)')\n",
    "        plt.ylabel('distance')\n",
    "        for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
    "            x = 0.5 * sum(i[1:3])\n",
    "            y = d[1]\n",
    "            if y > annotate_above:\n",
    "                plt.plot(x, y, 'o', c=c)\n",
    "                plt.annotate(\"%.3g\" % y, (x, y), xytext=(0, -5),\n",
    "                             textcoords='offset points',\n",
    "                             va='top', ha='center')\n",
    "        if max_d:\n",
    "            plt.axhline(y=max_d, c='k')\n",
    "    return ddata\n",
    "\n",
    "# Hclustering diagram\n",
    "max_d = 7 \n",
    "fancy_dendrogram(\n",
    "    Z,\n",
    "    truncate_mode='lastp',\n",
    "    p=12,\n",
    "    leaf_rotation=90.,\n",
    "    leaf_font_size=12.,\n",
    "    show_contracted=True,\n",
    "    annotate_above=10, \n",
    "    max_d=max_d,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "max_d = max_d\n",
    "clusters = fcluster(Z, max_d, criterion='distance')\n",
    "cluster_list = clusters.tolist()\n",
    "dfReturns['clusters'] = cluster_list\n",
    "from collections import Counter\n",
    "Counter(clusters)\n",
    "\n",
    "# plot clusters results with regression line\n",
    "%matplotlib inline\n",
    "facet = sns.lmplot(data=dfReturns, x='Risk', y='Returns', hue='clusters',palette='Set2',fit_reg=True, legend=True, legend_out=True)\n",
    "\n",
    "clusterext = dfReturns[dfReturns['clusters']==5]\n",
    "print(clusterext)\n",
    "stocknames = clusterext.index.tolist()\n",
    "\n",
    "clusterhighext = dfReturns[dfReturns['clusters']==3]\n",
    "print(clusterhighext)\n",
    "highstocknames = clusterhighext.index.tolist()\n",
    "\n",
    "clusterlowext = dfReturns[dfReturns['clusters']==1]\n",
    "print(clusterlowext)\n",
    "lowstocknames = clusterlowext.index.tolist()\n",
    "\n",
    "df_new2 = pd.DataFrame()\n",
    "df_new2 = df_new[df_new['name'].isin(stocknames)]\n",
    "df_new2 = df_new2.dropna()\n",
    "df_new2.to_csv('stocksmidrisk.csv',index=False)\n",
    "\n",
    "df_new3 = pd.DataFrame()\n",
    "df_new3 = df_new[df_new['name'].isin(highstocknames)]\n",
    "df_new3 = df_new3.dropna()\n",
    "df_new3.to_csv('stockshighrisk.csv',index=False)\n",
    "\n",
    "df_new4 = pd.DataFrame()\n",
    "df_new4 = df_new[df_new['name'].isin(lowstocknames)]\n",
    "df_new4 = df_new4.dropna()\n",
    "df_new4.to_csv('stockslowrisk.csv',index=False)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Part 3: Identify valuable stocks - potential stocks for investment\n",
    "# =============================================================================\n",
    "\n",
    "# Price to Earnings Ratio\n",
    "df_fin = pd.read_csv('financial_df.csv')\n",
    "df_fin.rename(columns={'stockname':'name'}, inplace=True)\n",
    "df_fin = df_fin[['name','quarter','price','pbt','eps','YoY']]   \n",
    "\n",
    "df_low = pd.read_csv('stockslowRisk.csv')\n",
    "df_low['risk'] = 'low risk'\n",
    "low_fin = set(df_low['name']).intersection(set(df_fin['name']))\n",
    "len(low_fin)\n",
    "low_fin_stocks = list(low_fin)\n",
    "df_low_fin = pd.merge(df_low,df_fin,how='inner',on='name')\n",
    "df_low_fin.to_csv('stockslowfin.csv',index=False)\n",
    "\n",
    "df_mid = pd.read_csv('stocksmidrisk.csv')\n",
    "df_mid['risk'] = 'mid risk'\n",
    "mid_fin = set(df_mid['name']).intersection(set(df_fin['name']))\n",
    "len(mid_fin) \n",
    "mid_fin_stocks = list(mid_fin)\n",
    "df_mid_fin = pd.merge(df_mid,df_fin,how='inner',on='name')\n",
    "df_mid_fin.to_csv('stocksmidfin.csv',index=False)\n",
    "\n",
    "df_hi = pd.read_csv('stockshighrisk.csv')\n",
    "df_hi['risk'] = 'high risk'\n",
    "hi_fin = set(df_hi['name']).intersection(set(df_fin['name']))\n",
    "len(hi_fin)\n",
    "hi_fin_stocks = list(hi_fin)\n",
    "df_hi_fin = pd.merge(df_hi,df_fin,how='inner',on='name')\n",
    "df_hi_fin.to_csv('stockshifin.csv',index=False)\n",
    "\n",
    "Alldf = pd.concat([df_low_fin,df_mid_fin,df_hi_fin], ignore_index=True)\n",
    "len(Alldf['name'].unique()) #143 companies in total\n",
    "Alldf.to_csv('combinedstockriskfinancial.csv',index=False)\n",
    "\n",
    "Alldf = pd.read_csv('combinedstockriskfinancial.csv')\n",
    "df_fin = Alldf[['name','risk','quarter','price','pbt','eps','YoY']]\n",
    "df_fin.drop_duplicates(subset=['name','price'],keep='first', inplace=True)\n",
    "\n",
    "# potential stocks filter\n",
    "investstock = df_fin[(df_fin['pbt_norm'] >= 0) & \n",
    "                     (df_fin['PE_ratio'] >= 0) &\n",
    "                     (df_fin['PE_ratio'] <=3) &\n",
    "                     (df_fin['YoY_norm'] >-1)]\n",
    "\n",
    "invstocknames = investstock['name'].tolist()\n",
    "len(invstocknames)\n",
    "print(invstocknames)\n",
    "\n",
    "Alldf['strategy'] = Alldf['name'].apply(lambda x: 'potentialgain' if x in invstocknames else 'potentialloss')\n",
    "newdf = Alldf[Alldf['strategy']=='potentialgain']\n",
    "\n",
    "newdf.drop(['open','quarter','price','pbt','eps','YoY','high','low','strategy'], axis=1, inplace=True)\n",
    "len(newdf['name'].unique().tolist())\n",
    "newdf.to_csv('potentialstock.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
